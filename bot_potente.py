import os
import asyncio
import aiohttp
import logging
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# ConfiguraciÃ³n
BOT_TOKEN = os.environ.get('BOT_TOKEN')
GEMINI_KEY = os.environ.get('GEMINI_KEY', 'AIzaSyAhyrzgcjygttXeyi4TUXfQa9CS3A0RHhQ')
OPENAI_KEY = os.environ.get('OPENAI_KEY')
PORT = int(os.environ.get('PORT', 10000))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MotorAI:
    def __init__(self):
        self.session = None
        self.cache = {}
    
    async def get_session(self):
        if not self.session:
            self.session = aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10))
        return self.session

    async procesar_mensaje(self, texto: str, user_id: int) -> dict:
        """Procesa con mÃºltiples AIs inteligentemente"""
        
        # Cache simple
        cache_key = f"{user_id}:{texto[:50]}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # SelecciÃ³n inteligente de AI
        ai_seleccionada = self._seleccionar_ai(texto, user_id)
        
        resultado = await self._llamar_ai(ai_seleccionada, texto)
        
        if resultado['exito']:
            self.cache[cache_key] = resultado
            # Limpiar cache viejo
            if len(self.cache) > 100:
                self.cache.clear()
        
        return resultado
    
    def _seleccionar_ai(self, texto: str, user_id: int) -> str:
        """Selecciona la mejor AI para el contexto"""
        texto = texto.lower()
        
        if any(palabra in texto for palabra in ['cÃ³digo', 'programar', 'python']):
            return 'gemini'
        elif any(palabra in texto for palabra in ['creativo', 'escribir', 'historia']):
            return 'openai' if OPENAI_KEY else 'gemini'
        elif any(palabra in texto for palabra in ['rÃ¡pido', 'urgente']):
            return 'gemini'  # Gemini es mÃ¡s rÃ¡pido
        else:
            return 'gemini'  # Por defecto
    
    async def _llamar_ai(self, ai_nombre: str, mensaje: str) -> dict:
        """Llama a la API especÃ­fica"""
        try:
            if ai_nombre == 'gemini' and GEMINI_KEY:
                return await self._llamar_gemini(mensaje)
            elif ai_nombre == 'openai' and OPENAI_KEY:
                return await self._llamar_openai(mensaje)
            else:
                return await self._llamar_gemini(mensaje)  # Fallback a Gemini
        except Exception as e:
            logger.error(f"Error en {ai_nombre}: {e}")
            return {'exito': False, 'respuesta': f'Error: {str(e)}', 'ai': ai_nombre}
    
    async def _llamar_gemini(self, mensaje: str) -> dict:
        """Google Gemini - Potente y gratuito"""
        session = await self.get_session()
        url = f"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key={GEMINI_KEY}"
        
        payload = {
            "contents": [{
                "parts": [{"text": f"Responde en espaÃ±ol de forma Ãºtil y precisa: {mensaje}"}]
            }],
            "generationConfig": {
                "temperature": 0.7,
                "maxOutputTokens": 1000,
                "topP": 0.8
            }
        }
        
        async with session.post(url, json=payload) as response:
            if response.status == 200:
                data = await response.json()
                if 'candidates' in data and data['candidates']:
                    texto = data['candidates'][0]['content']['parts'][0]['text']
                    return {'exito': True, 'respuesta': texto, 'ai': 'gemini'}
            
            return {'exito': False, 'respuesta': 'Error en Gemini', 'ai': 'gemini'}
    
    async def _llamar_openai(self, mensaje: str) -> dict:
        """OpenAI GPT - Para respuestas creativas"""
        session = await self.get_session()
        url = "https://api.openai.com/v1/chat/completions"
        headers = {"Authorization": f"Bearer {OPENAI_KEY}"}
        
        payload = {
            "model": "gpt-3.5-turbo",
            "messages": [{"role": "user", "content": mensaje}],
            "max_tokens": 800,
            "temperature": 0.7
        }
        
        async with session.post(url, headers=headers, json=payload) as response:
            if response.status == 200:
                data = await response.json()
                texto = data['choices'][0]['message']['content']
                return {'exito': True, 'respuesta': texto, 'ai': 'openai'}
            
            return {'exito': False, 'respuesta': 'Error en OpenAI', 'ai': 'openai'}

# Motor global
motor_ai = MotorAI()

async def inicio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Comando start mejorado"""
    user = update.message.from_user
    
    texto_bienvenida = f"""
ğŸ¤– **BOT AI POTENTE ACTIVADO**

Â¡Hola {user.first_name}! Soy tu asistente con **inteligencia artificial avanzada**.

ğŸš€ **CaracterÃ­sticas:**
â€¢ MÃºltiples motores AI (Gemini + OpenAI)
â€¢ SelecciÃ³n inteligente por contexto
â€¢ Respuestas rÃ¡pidas y precisas
â€¢ Optimizado para producciÃ³n

ğŸ’¡ **Simplemente escribe tu pregunta...**
"""
    await update.message.reply_text(texto_bienvenida, parse_mode='Markdown')

async def chat_ai(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Procesa mensajes con AI potente"""
    mensaje_usuario = update.message.text
    user_id = update.message.from_user.id
    
    # Mensaje de procesamiento
    mensaje_procesando = await update.message.reply_text("âš¡ Procesando con motor AI...")
    
    try:
        # Procesar con motor AI
        inicio_tiempo = time.time()
        resultado = await motor_ai.procesar_mensaje(mensaje_usuario, user_id)
        tiempo_procesamiento = time.time() - inicio_tiempo
        
        if resultado['exito']:
            respuesta = f"""
ğŸ§  **RESPUESTA AI** ({resultado['ai'].upper()})
â±ï¸ {tiempo_procesamiento:.2f}s

{resultado['respuesta']}

ğŸ”§ *Procesado con arquitectura multi-AI*
"""
        else:
            respuesta = f"""
âŒ **ERROR EN MOTOR AI**

{resultado['respuesta']}

âš ï¸ *Reintentando automÃ¡ticamente...*
"""
        
        await context.bot.edit_message_text(
            chat_id=update.message.chat_id,
            message_id=mensaje_procesando.message_id,
            text=respuesta,
            parse_mode='Markdown'
        )
        
    except Exception as e:
        await context.bot.edit_message_text(
            chat_id=update.message.chat_id,
            message_id=mensaje_procesando.message_id,
            text="âŒ **Error temporal en el sistema AI**"
        )

async def estado(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Muestra estado del sistema"""
    estado_texto = """
ğŸ“Š **SISTEMA AI - ESTADO**

ğŸŸ¢ **BOT:** Operativo
ğŸ¤– **MOTORES AI:** 
â€¢ Gemini: âœ… Activo
â€¢ OpenAI: {} Activo
ğŸ’¾ **CACHE:** Activado
ğŸš€ **RENDIMIENTO:** Optimizado

*Sistema funcionando al 100%*
""".format("âœ…" if OPENAI_KEY else "âŒ")
    
    await update.message.reply_text(estado_texto, parse_mode='Markdown')

async def herramientas(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Muestra herramientas disponibles"""
    herramientas_texto = """
ğŸ› ï¸ **HERRAMIENTAS AI DISPONIBLES**

ğŸ§  **Motores de Inteligencia:**
â€¢ Gemini Pro - Para cÃ³digo y respuestas tÃ©cnicas
â€¢ OpenAI GPT - Para creatividad y escritura

ğŸ”§ **Funcionalidades:**
â€¢ AnÃ¡lisis de contexto automÃ¡tico
â€¢ SelecciÃ³n inteligente de AI
â€¢ Cache de respuestas
â€¢ Procesamiento optimizado

ğŸ’¡ **Comandos:**
/start - Iniciar bot
/estado - Ver estado del sistema
/herramientas - Esta ayuda

*Escribe cualquier pregunta para comenzar*
"""
    await update.message.reply_text(herramientas_texto, parse_mode='Markdown')

def main():
    """FunciÃ³n principal optimizada"""
    if not BOT_TOKEN:
        logger.error("âŒ BOT_TOKEN no configurado")
        return
    
    try:
        # Crear aplicaciÃ³n
        application = Application.builder().token(BOT_TOKEN).build()
        
        # Handlers
        application.add_handler(CommandHandler("start", inicio))
        application.add_handler(CommandHandler("estado", estado))
        application.add_handler(CommandHandler("herramientas", herramientas))
        application.add_handler(CommandHandler("help", herramientas))
        application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat_ai))
        
        logger.info("ğŸš€ BOT AI POTENTE INICIANDO")
        logger.info(f"ğŸ”‘ Gemini: {'âœ…' if GEMINI_KEY else 'âŒ'}")
        logger.info(f"ğŸ”‘ OpenAI: {'âœ…' if OPENAI_KEY else 'âŒ'}")
        
        # Webhook para Render
        application.run_webhook(
            listen="0.0.0.0",
            port=PORT,
            url_path=BOT_TOKEN,
            webhook_url=f"https://telegram-bot-simple-y7lc.onrender.com/{BOT_TOKEN}",
            drop_pending_updates=True
        )
        
    except Exception as e:
        logger.error(f"âŒ ERROR: {e}")

if __name__ == '__main__':
    import time
    main()
